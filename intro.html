<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Introduction</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Super Resolution</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Abstract</a></li>
							<li class="active"><a href="intro.html">Introduction</a></li>
							<li><a href="dataset.html">Dataset</a></li>
							<li><a href="method.html">Method</a></li>
							<li><a href="image_preprocessing.html">Preprocessing</a></li>
							<li><a href="evaluation.html">Evaluation</a></li>
							<li><a href="conclusion.html">Conclusion</a></li>
							<li><a href="demo.html">Demo</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://github.com/rushk99/Image-Super-Resolution-SRGAN" target="_blank" rel="noopener noreferrer" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1>Introduction</h1>
								</header>
								<div class="image main"><img src="images/intro.jpg" alt="" /></div>
								<p style="text-align:center">
									Fig 1. Low Resolution Image vs Super Resolved Image
								</p>
								<br>
								<br>
								<p>The highly challenging task of reconstructing a high-resolution (HR) image from its low-resolution (LR)
									counterpart is referred to as super-resolution (SR). SR
									received substantial attention from within the computer
									vision research community and has a wide range of
									applications: 
									<br>
									<br>&emsp;&emsp;1. Surveillance: to detect, identify, and perform facial recognition on low-resolution images obtained from security cameras. 
									<br>&emsp;&emsp;2. Medical: capturing high-resolution MRI images can be tricky when it comes to scan time, spatial coverage, and signal-to-noise ratio (SNR).
									<br>
									<br>
									The ill-posed aspect of the underdetermined SR problem is most obvious for high upscaling factors, which often lack texture detail in the reconstructed SR images.
									The optimization target of supervised
									SR algorithms is commonly the minimization of the mean
									squared error (MSE) between the recovered HR image
									and the ground truth. This is convenient as minimizing
									MSE also maximizes the peak signal-to-noise ratio (PSNR),
									which is a common measure used to evaluate and compare
									SR algorithms. However, the ability of MSE (and
									PSNR) to capture perceptually relevant differences, such
									as high texture detail, is very limited as they are defined
									based on pixel-wise image differences. 
									<br>
									<br>Highest PSNR does not
									necessarily reflect the perceptually better SR result.
									
									Perceptual difference between the super-resolved and original image means that the recovered image is not photorealistic.
									In this project we implement a super-resolution generative
									adversarial network (SRGAN) for which we employ a
									deep residual network (ResNet) with skip-connection and
									diverge from MSE as the sole optimization target. Different
									from previous works, the author defined a novel perceptual loss using high-level feature maps of the VGG-16 network
									combined with a discriminator that distinguishes super resolved images from their respective HR reference images. solutions
									perceptually hard to distinguish from the HR reference
									images. An example photo-realistic image that was superresolved with a 4Ã— upscaling factor is shown in Figure 1.</p>

								<p>In the framework of adversarial nets, the generative model is compared to an adversary while simultaneously training two models: 
									the discriminative model D and the generative model G, which estimates the probability that a sample will come from the training data 
									rather than G. The goal of the training process for G is to increase the likelihood that D will make a mistake. This framework corresponds 
									to a minimax two-player game, where we minimize the generator loss and maximize the discriminator loss.
								
									<p>
							</section>

					</div>
			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>